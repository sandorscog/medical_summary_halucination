{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f60aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def add_project_root(levels_up: int = 1):\n",
    "    \"\"\"Adds the project root to sys.path for Jupyter or scripts.\"\"\"\n",
    "    root = Path().resolve()\n",
    "    for _ in range(levels_up):\n",
    "        root = root.parent\n",
    "    if str(root) not in sys.path:\n",
    "        sys.path.append(str(root))\n",
    "add_project_root() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545d77fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandor/.conda/envs/verdi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sandor/.conda/envs/verdi/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/sandor/.conda/envs/verdi/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import evaluate\n",
    "\n",
    "from modules.pipeline import complete_pipeline\n",
    "from modules.summarizer import Summarizer\n",
    "from modules.SummaryManager import EvalSummaryManager\n",
    "from modules.summary_enhancer import enhancer\n",
    "from modules.data_handler import load_discharges, load_patient_data\n",
    "from modules.context_handler import context_builder_text, context_builder_json, build_discharge_windows, get_patient_window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOMPOSITION_PROMPT_TEMPLATE = '''\n",
    "\n",
    "You are a medical information analyst. Your task is to parse the entire medical summary below and decompose it into a complete list of fine-grained, verifiable claims. These claims will be used to fact-check the summary against a full patient record.\n",
    "\n",
    "Each claim must be a single, self-contained medical fact, finding, instruction, or patient-reported statement.\n",
    "\n",
    "**Extraction Rules:**\n",
    "1.  **Split Lists:** Decompose lists of conditions, symptoms, findings, or plans into separate claims (e.g., \"history of A, B, and C\" becomes three separate claims).\n",
    "2.  **Keep Instructions Intact:** A single medication (e.g., \"Furosemide 40mg daily\") is one complete claim. Do not split the drug from its dosage.\n",
    "3.  **Be Self-Contained:** Resolve all pronouns (e.g., \"She,\" \"He\") to \"The patient.\"\n",
    "4.  **Extract All Details:** Capture demographics, past medical history (PMH), symptoms, lab results, imaging findings, diagnoses, medications, and follow-up plans.\n",
    "5.  **Output Format:** Provide the output as a simple list of claims one in each line.\n",
    "\n",
    "---\n",
    "### Example 1\n",
    "\n",
    "**Full Summary:**\n",
    "The patient, a female with a history of HCV cirrhosis with ascites, HIV on ART, IV drug use, COPD, bipolar disorder, and PTSD, presented with worsening abdominal distension and pain. She had discontinued her Lasix and Spironolactone prior to admission due to feeling that they weren't effective and wanting to avoid \"chemicals.\"During hospitalization, the patient's ascites was managed with diuretics (Furosemide 40mg and Spironolactone 50mg daily). Paracentesis was attempted in the ED but was unsuccessful. Lab results showed elevated liver enzymes (ALT, AST, Alk Phos, Total Bili), and a low platelet count. A CXR showed no acute cardiopulmonary process. Ultrasound revealed liver nodularity, signs of portal hypertension (ascites and splenomegaly), and cholelithiasis. The patient was scheduled for follow-up with her current PCP, a new PCP (Dr. ___), and the Liver Clinic for EGD and ___. She was discharged home in a clear and coherent mental state, alert, interactive, and ambulatory, with a diagnosis of ascites from portal hypertension. She was instructed to continue taking Furosemide 40mg and Spironolactone 50mg daily, adhere to a low-salt diet, and follow up with the Liver Clinic.\n",
    "\n",
    "\n",
    "**Claims:**\n",
    "The patient is female.\n",
    "\n",
    "The patient has a history of HCV cirrhosis with ascites.\n",
    "\n",
    "The patient has a history of HIV on ART.\n",
    "\n",
    "The patient has a history of IV drug use.\n",
    "\n",
    "The patient has a history of COPD.\n",
    "\n",
    "The patient has a history of bipolar disorder.\n",
    "\n",
    "The patient has a history of PTSD.\n",
    "\n",
    "The patient presented with worsening abdominal distension.\n",
    "\n",
    "The patient presented with worsening abdominal pain.\n",
    "\n",
    "The patient had discontinued her Lasix prior to admission.\n",
    "\n",
    "The patient had discontinued her Spironolactone prior to admission.\n",
    "\n",
    "The patient's reason for discontinuing was feeling [the drugs] weren't effective.\n",
    "\n",
    "The patient's reason for discontinuing was wanting to avoid \"chemicals.\"\n",
    "\n",
    "The patient's ascites was managed with Furosemide 40mg daily during hospitalization.\n",
    "\n",
    "The patient's ascites was managed with Spironolactone 50mg daily during hospitalization.\n",
    "\n",
    "Paracentesis was attempted in the ED.\n",
    "\n",
    "The paracentesis attempt in the ED was unsuccessful.\n",
    "\n",
    "Lab results showed elevated liver enzymes (ALT, AST, Alk Phos, Total Bili).\n",
    "\n",
    "Lab results showed a low platelet count.\n",
    "\n",
    "A CXR showed no acute cardiopulmonary process.\n",
    "\n",
    "Ultrasound revealed liver nodularity.\n",
    "\n",
    "Ultrasound revealed signs of portal hypertension (ascites and splenomegaly).\n",
    "\n",
    "Ultrasound revealed cholelithiasis.\n",
    "\n",
    "The patient was scheduled for follow-up with her current PCP.\n",
    "\n",
    "The patient was scheduled for follow-up with a new PCP (Dr. ___).\n",
    "\n",
    "The patient was scheduled for follow-up with the Liver Clinic for EGD.\n",
    "\n",
    "The patient was scheduled for follow-up with the Liver Clinic for ___.\n",
    "\n",
    "The patient was discharged home.\n",
    "\n",
    "The patient's mental state at discharge was clear and coherent.\n",
    "\n",
    "The patient's status at discharge was alert.\n",
    "\n",
    "The patient's status at discharge was interactive.\n",
    "\n",
    "The patient's status at discharge was ambulatory.\n",
    "\n",
    "The patient's diagnosis was ascites from portal hypertension.\n",
    "\n",
    "The patient was instructed to continue taking Furosemide 40mg daily.\n",
    "\n",
    "The patient was instructed to continue taking Spironolactone 50mg daily.\n",
    "\n",
    "The patient was instructed to adhere to a low-salt diet.\n",
    "\n",
    "The patient was instructed to follow up with the Liver Clinic.\n",
    "\n",
    "---\n",
    "### New summary (YOUR TASK)\n",
    "\n",
    "**Full Summary:**\n",
    "{summary_text}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6cf468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preload the NLI model once (outside function for efficiency)\n",
    "nli = pipeline(\"text-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "\n",
    "def decomp_judge_subpipeline():\n",
    "    discharges = load_discharges()\n",
    "    patients_data = load_patient_data()\n",
    "    discharge_windows = build_discharge_windows(discharges)\n",
    "\n",
    "    summarizer = Summarizer(model='gemini')\n",
    "\n",
    "    results = []\n",
    "    idx=0\n",
    "\n",
    "    for _, case in discharges.iterrows():\n",
    "        subject_id = case['subject_id']\n",
    "        hadm_id = case['hadm_id']\n",
    "        original_text = case['text']\n",
    "\n",
    "\n",
    "        # Retrieve contextual data\n",
    "        context_df = get_patient_window_data(\n",
    "            subject_id=subject_id,\n",
    "            hadm_id=hadm_id,\n",
    "            windows_dict=discharge_windows,\n",
    "            patient_df=patients_data,\n",
    "            time_col='starttime'\n",
    "        )\n",
    "        context_json = context_builder_json(context_df)\n",
    "        context_textual = context_builder_text(context_json)\n",
    "\n",
    "\n",
    "        ### Summarization -------------------------------------------------------------\n",
    "        summary_response = summarizer.summ(original_text)\n",
    "\n",
    "\n",
    "        ### Decomposition -------------------------------------------------------------\n",
    "        decomposition_prompt = DECOMPOSITION_PROMPT_TEMPLATE.format(\n",
    "            summary_text=summary_response\n",
    "        )\n",
    "        decomp_response = summarizer.model.generate_content(decomposition_prompt).text\n",
    "\n",
    "\n",
    "        ### Judging -------------------------------------------------------------------\n",
    "        claims = [c.strip() for c in decomp_response.splitlines() if c.strip()]\n",
    "        judged_claims_list = []\n",
    "        judged_claims_text_list = []\n",
    "\n",
    "        # Chunking with overlap\n",
    "        premise = f\"Discharge:\\n{original_text}\\nPatient context:\\n{context_textual}\"\n",
    "\n",
    "        chunk_size = 2000          # text length per chunk\n",
    "        overlap = 200              # number of overlapping characters\n",
    "        premise_chunks = [\n",
    "            premise[i : i + chunk_size]\n",
    "            for i in range(0, len(premise), chunk_size - overlap)\n",
    "        ]\n",
    "\n",
    "        # Run for each \n",
    "        for claim in claims:\n",
    "\n",
    "            best_label, best_score = None, 0.0\n",
    "            for chunk in premise_chunks:\n",
    "                result = nli(f\"{chunk} </s> {claim}\")\n",
    "                label, score = result[0][\"label\"], result[0][\"score\"]\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_label, best_score = label, score\n",
    "\n",
    "                # Early stop\n",
    "                if label == \"ENTAILMENT\" and score > 0.85:\n",
    "                    break\n",
    "\n",
    "            judged_claim = f\"{claim}-{best_label}-{best_score:.3f}\"\n",
    "            judged_claims_list.append(judged_claim)\n",
    "\n",
    "            judged_claim_text = f\"{claim} - {best_label} - {best_score:.3f}\"\n",
    "            judged_claims_text_list.append(judged_claim_text)\n",
    "\n",
    "        judged_claims_text = \"\\n\".join(judged_claims_list)\n",
    "        \n",
    "\n",
    "\n",
    "        print('discharge: \\n', original_text, '\\nsummary:\\n', summary_response,'\\ndecomp:\\n', decomp_response,'\\ncontext:\\n', context_textual, '\\n*****\\nJUDGED CLAIMS\\n', judged_claims_text,'\\n\\n',)\n",
    "\n",
    "        ## Claim Correction --------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        ## Text Compiler ------------------------------------------------------------------------------------------\n",
    "        prompt = '''\n",
    "            You are a precise and concise medical writer.\n",
    "            Your task is to merge and rewrite the following factual sentences into a single, well-structured text.\n",
    "\n",
    "            Guidelines:\n",
    "             - Only combine sentences if their meanings are fully equivalent or trivially overlapping.\n",
    "             - Maintain all factual information — do not omit or change any details.\n",
    "             - If there is any uncertainty about whether two sentences mean the same thing, keep both.\n",
    "             - Preserve the order of the claims\n",
    "             - Use a natural narrative tone, combining ideas logically (e.g., history -> reason for admission -> findings).\n",
    "             - If multiple facts are related, integrate them into one flowing sentence.\n",
    "             - Preserve medical accuracy, structure, and readability.\n",
    "             - Do not speculate or interpret beyond what is written.\n",
    "\n",
    "\n",
    "            Example 1:\n",
    "            Input:\n",
    "            The patient reported self-discontinuing her diuretics.\n",
    "            The patient reported self-discontinuing Lasix.\n",
    "            The patient reported self-discontinuing Spironolactone.\n",
    "            The patient reported not adhering to a sodium-restricted diet.\n",
    "            Self-discontinuing diuretics and not adhering to a sodium-restricted diet likely contributed to the worsening ascites.\n",
    "\n",
    "\n",
    "            Output:\n",
    "            The patient reported self-discontinuing her diuretics, including Lasix and Spironolactone, and not adhering to a sodium-restricted diet, both of which likely contributed to her worsening ascites.\n",
    "\n",
    "\n",
    "            Example 2:\n",
    "            Input:\n",
    "            The patient has a history of HCV cirrhosis.\n",
    "            The patient has a history of HIV on ART.\n",
    "            The patient has a history of COPD.\n",
    "            The patient has a history of bipolar disorder.\n",
    "            The patient has a history of PTSD.\n",
    "\n",
    "            Output:\n",
    "            The patient has a history of HCV cirrhosis, HIV on ART, COPD, bipolar disorder, and PTSD.\n",
    "\n",
    "            *NOW AGGREGATE (YOUR TASK)*:\n",
    "            \n",
    "\n",
    "        '''\n",
    "        prompt = prompt + decomp_response\n",
    "\n",
    "        enhanced_summary = summarizer.model.generate_content(prompt).text\n",
    "\n",
    "        ## Compute Metrics ---------------------------------------------------------------------------------------\n",
    "        # summary_response\n",
    "        # enhanced_summary\n",
    "\n",
    "        # BERT_score\n",
    "\n",
    "        rouge = evaluate.load('rouge')\n",
    "        rouge_scores = rouge.compute(\n",
    "            predictions=[summary_response, enhanced_summary],\n",
    "            references=[original_text, original_text],\n",
    "            use_aggregator=False\n",
    "        )\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"hadm_id\": hadm_id,\n",
    "            \"original_text\": original_text,\n",
    "            \"context_textual\": context_textual,\n",
    "            \"base_summary\": summary_response,\n",
    "            \"decomposed_summary_text\": judged_claims_text,\n",
    "            \"judged_claims\": judged_claims_list,\n",
    "            # \"nli_results\": nli_results\n",
    "            \"rouge_base_summary\": {\n",
    "                \"rouge1\": rouge_scores[\"rouge1\"][0],\n",
    "                \"rouge2\": rouge_scores[\"rouge2\"][0],\n",
    "                \"rougeL\": rouge_scores[\"rougeL\"][0],\n",
    "                \"rougeLsum\": rouge_scores[\"rougeLsum\"][0],\n",
    "            },\n",
    "            \"rouge_enhanced_summary\": {\n",
    "                \"rouge1\": rouge_scores[\"rouge1\"][1],\n",
    "                \"rouge2\": rouge_scores[\"rouge2\"][1],\n",
    "                \"rougeL\": rouge_scores[\"rougeL\"][1],\n",
    "                \"rougeLsum\": rouge_scores[\"rougeLsum\"][1],\n",
    "            },\n",
    "        })\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv('results_df.csv', index=False)\n",
    "        print(f\"Checkpoint saved ({idx}/{len(discharges)}) → {'results_df.csv'}\")\n",
    "        idx += 1\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('results_df.csv', index=False)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686eb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_judge_subpipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = Summarizer(model='gemini')\n",
    "\n",
    "prompt = '''\n",
    "    You are a careful medical summarizer.\n",
    "    Your task is to merge and unify sentences that clearly describe the same information, while keeping all distinct clinical facts intact.\n",
    "\n",
    "    Guidelines:\n",
    "        - Only combine sentences if their meanings are fully equivalent or trivially overlapping.\n",
    "        - Never remove or alter any factual information.\n",
    "        - If there is any uncertainty about whether two sentences mean the same thing, keep both.\n",
    "        - Preserve the order of the claims\n",
    "        - Preserve medical accuracy, structure, and readability.\n",
    "        - Output the result as a clear, concise list of sentences that retain all original meaning.\n",
    "\n",
    "\n",
    "    Example 1:\n",
    "    Input:\n",
    "    The patient reported self-discontinuing her diuretics.\n",
    "    The patient reported self-discontinuing Lasix.\n",
    "    The patient reported self-discontinuing Spironolactone.\n",
    "    The patient reported not adhering to a sodium-restricted diet.\n",
    "    Self-discontinuing diuretics and not adhering to a sodium-restricted diet likely contributed to the worsening ascites.\n",
    "    The patient has a history of HCV cirrhosis.\n",
    "    The patient has a history of HIV on ART.\n",
    "    The patient has a history of COPD.\n",
    "    The patient has a history of bipolar disorder.\n",
    "    The patient has a history of PTSD.\n",
    "\n",
    "    Output:\n",
    "    The patient has a history of HCV cirrhosis, HIV on ART, COPD, bipolar disorder, and PTSD. She reported self-discontinuing her diuretics, including Lasix and Spironolactone, and not adhering to a sodium-restricted diet, both of which likely contributed to her worsening ascites.\n",
    "\n",
    "\n",
    "    Example 2:\n",
    "    Input:\n",
    "    The patient is female.\n",
    "    The patient has a history of HIV on HAART.\n",
    "    The patient has a history of COPD.\n",
    "    The patient has a history of HCV cirrhosis.\n",
    "    The patient's HCV cirrhosis is complicated by ascites.\n",
    "    The patient's HCV cirrhosis is complicated by hepatic encephalopathy.\n",
    "    The patient was admitted due to abdominal fullness.\n",
    "    The patient was admitted due to abdominal discomfort.\n",
    "    The patient had been recently discharged after a paracentesis.\n",
    "    The patient experienced re-accumulation of ascites.\n",
    "    The patient experienced increased abdominal distention.\n",
    "    The patient experienced increased abdominal pain.\n",
    "    The patient experienced visual hallucinations.\n",
    "    The patient experienced forgetfulness.\n",
    "    The patient's visual hallucinations are suggestive of hepatic encephalopathy.\n",
    "    Upon discharge, the patient was independently ambulatory.\n",
    "    Upon discharge, the patient had clear mental status.\n",
    "    The patient's primary discharge diagnosis was diuretic refractory ascites.\n",
    "    The patient's secondary discharge diagnosis was HCV cirrhosis.\n",
    "    The patient's secondary discharge diagnosis was HIV.\n",
    "    The patient's secondary discharge diagnosis was hyponatremia.\n",
    "    The patient's secondary discharge diagnosis was COPD.\n",
    "    The patient was instructed to continue her low-sodium diet.\n",
    "    The patient was instructed to continue her fluid restriction.\n",
    "    The patient was advised to return to the emergency room for any worsening abdominal pain.\n",
    "    The patient was advised to return to the emergency room for any fever.\n",
    "    The patient's discharge medications included her HIV medications.\n",
    "    The patient's discharge medications included lactulose.\n",
    "    The patient's discharge medications included rifaximin.\n",
    "    The patient's discharge medications included Bactrim.\n",
    "\n",
    "    Output:\n",
    "    The patient is a female with a history of HCV cirrhosis complicated by ascites and hepatic encephalopathy, HIV on HAART, COPD, and hyponatremia. She was admitted with abdominal fullness and discomfort following a recent discharge after paracentesis, due to re-accumulation of ascites associated with increased abdominal distention and pain. She also experienced visual hallucinations and forgetfulness, findings suggestive of hepatic encephalopathy. Upon discharge, she was independently ambulatory and had a clear mental status. Her primary discharge diagnosis was diuretic-refractory ascites, with secondary diagnoses of HCV cirrhosis, HIV, hyponatremia, and COPD. She was instructed to continue a low-sodium diet and fluid restriction, and to return to the emergency room for any worsening abdominal pain or fever. Discharge medications included her HIV regimen, lactulose, rifaximin, and Bactrim.\n",
    "\n",
    "    *NOW AGGREGATE (YOUR TASK)*:\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "claims = '''\n",
    "\n",
    "    The patient is female.\n",
    "    The patient is ___ years old.\n",
    "    The patient is healthy.\n",
    "    The patient was admitted to Urology.\n",
    "    The patient was admitted for a right renal mass.\n",
    "    The right renal mass was suspicious for Renal Cell Carcinoma (RCC).\n",
    "    The right renal mass was an incidental finding on MRI.\n",
    "    The patient's past medical history includes nonspecific right axis deviation.\n",
    "    The patient's past medical history includes a cesarean section.\n",
    "    The patient has no known drug allergies.\n",
    "    The patient's diet was gradually advanced.\n",
    "    The remainder of the patient's hospital course was unremarkable.\n",
    "    At discharge, the patient was in stable condition.\n",
    "    At discharge, the patient was ambulating independently.\n",
    "    At discharge, the patient was tolerating a diet.\n",
    "    At discharge, the patient was voiding without difficulty.\n",
    "    At discharge, the patient's pain was well-controlled on oral medication.\n",
    "    Discharge medications included hydrocodone-acetaminophen for breakthrough pain.\n",
    "    Discharge medications included docusate sodium for constipation.\n",
    "    The patient was discharged home.\n",
    "    The patient was instructed to avoid bathing.\n",
    "    The patient was instructed to avoid swimming.\n",
    "    The patient was instructed to limit lifting to under 10 pounds.\n",
    "    The patient was instructed to avoid driving until her follow-up.\n",
    "    The patient was instructed to use Tylenol as first-line pain relief.\n",
    "    The patient was advised to resume home medications.\n",
    "    The patient was advised to hold NSAIDs until follow-up.\n",
    "    The patient was advised to seek medical attention for fevers above 101.5 F.\n",
    "    The patient was advised to seek medical attention for vomiting.\n",
    "    The patient was advised to seek medical attention for worsening incision.\n",
    "    A follow-up appointment with Urology in 3 weeks was scheduled.\n",
    "    The patient's final diagnosis was renal cell carcinoma.\n",
    "\n",
    "'''\n",
    "\n",
    "prompt = prompt + claims\n",
    "\n",
    "output = summarizer.model.generate_content(prompt).text\n",
    "\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = Summarizer(model='gemini')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5558fd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandor/.conda/envs/verdi/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing case 1 - subject 10000032, hadm 22595853\n",
      " Starting summary...\n",
      "Decomposing into claims...\n",
      "['The patient is female.', 'The patient has a history of HCV cirrhosis.', 'The patient has a history of HIV on ART.', 'The patient has a history of COPD.']\n",
      "Processing 4 claims...\n",
      "Compiling new summary\n",
      "ERROR!! on case 1: sequence item 0: expected str instance, dict found\n",
      "\n",
      "Processing case 2 - subject 10000032, hadm 22841357\n",
      " Starting summary...\n",
      "Decomposing into claims...\n",
      "['The patient is female.', 'The patient has a history of HIV on HAART.', 'The patient has a history of COPD.', 'The patient has a history of HCV cirrhosis complicated by ascites.']\n",
      "Processing 4 claims...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcomplete_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Personal/UFMG/Mestrado/dissertacao/projeto/modules/pipeline.py:170\u001b[0m, in \u001b[0;36mcomplete_pipeline\u001b[0;34m(save_path)\u001b[0m\n\u001b[1;32m    167\u001b[0m print(claims)\n\u001b[1;32m    169\u001b[0m print(f'Processing {len(claims)} claims...')\n\u001b[0;32m--> 170\u001b[0m # judged_claims = judge(claims, discharge_text, context_json)\n\u001b[1;32m    171\u001b[0m judged_claims = summarizer.judge(claims, discharge_text, context_text) ## TEST WITH CONTEXTUAL TEXT\n\u001b[1;32m    172\u001b[0m final_claims = claim_corretor(judged_claims, discharge_text, context_json)\n",
      "File \u001b[0;32m~/Personal/UFMG/Mestrado/dissertacao/projeto/modules/summarizer.py:174\u001b[0m, in \u001b[0;36mSummarizer.judge\u001b[0;34m(self, claims, discharge_text, context_text)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Evaluate the claim against each chunk\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m premise_chunks:\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# your original input format: chunk </s> claim\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnli\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m </s> \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclaim\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     label  \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    176\u001b[0m     score  \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/pipelines/base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/pipelines/base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1146\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1147\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1886\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1882\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1883\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1884\u001b[0m     )\n\u001b[0;32m-> 1886\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1902\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[1;32m   1904\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1594\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1591\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1594\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1202\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1195\u001b[0m             encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1196\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m             output_attentions,\n\u001b[1;32m   1200\u001b[0m         )\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1202\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:671\u001b[0m, in \u001b[0;36mBartEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    669\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(hidden_states))\n\u001b[1;32m    670\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m--> 671\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/verdi/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "complete_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
