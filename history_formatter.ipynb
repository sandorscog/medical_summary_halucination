{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e288e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_discharge_table(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load discharge table with required columns:\n",
    "    ['note_id', 'subject_id', 'hadm_id', 'note_type', 'note_seq', 'charttime', 'storetime']\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, parse_dates=['charttime', 'storetime'])\n",
    "    df = df.sort_values(['subject_id', 'storetime']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_discharge_windows(discharge_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given discharge table, create a dataframe of time windows per subject.\n",
    "    Each window represents the time between consecutive storetime values.\n",
    "    \"\"\"\n",
    "    discharge_df = discharge_df.copy()\n",
    "    discharge_df['window_start'] = discharge_df.groupby('subject_id')['storetime'].shift(1)\n",
    "    discharge_df['window_end'] = discharge_df['storetime']\n",
    "\n",
    "    # The first discharge has no previous storetime, so window_start can be NaT or -inf\n",
    "    discharge_df['window_start'] = discharge_df['window_start'].fillna(pd.Timestamp.min)\n",
    "    return discharge_df[['subject_id', 'hadm_id', 'window_start', 'window_end']]\n",
    "\n",
    "\n",
    "def extract_rows_in_windows(data_df: pd.DataFrame,\n",
    "                            discharge_windows: pd.DataFrame,\n",
    "                            time_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generic function to filter rows from data_df that fall within discharge windows.\n",
    "    Arguments:\n",
    "        data_df: dataframe with at least ['subject_id', time_col]\n",
    "        discharge_windows: dataframe returned from build_discharge_windows\n",
    "        time_col: name of timestamp column in data_df (must be datetime)\n",
    "    Returns:\n",
    "        DataFrame of rows joined to their corresponding discharge window\n",
    "    \"\"\"\n",
    "    data_df = data_df.copy()\n",
    "    data_df[time_col] = pd.to_datetime(data_df[time_col])\n",
    "\n",
    "    results = []\n",
    "    for subj, subj_windows in discharge_windows.groupby('subject_id'):\n",
    "        subj_data = data_df[data_df['subject_id'] == subj]\n",
    "        if subj_data.empty:\n",
    "            continue\n",
    "\n",
    "        for _, row in subj_windows.iterrows():\n",
    "            mask = (subj_data[time_col] > row['window_start']) & (subj_data[time_col] <= row['window_end'])\n",
    "            matched = subj_data.loc[mask].copy()\n",
    "            if not matched.empty:\n",
    "                matched['hadm_id_window'] = row['hadm_id']\n",
    "                matched['window_start'] = row['window_start']\n",
    "                matched['window_end'] = row['window_end']\n",
    "                results.append(matched)\n",
    "\n",
    "    if results:\n",
    "        return pd.concat(results, ignore_index=True)\n",
    "    return pd.DataFrame(columns=list(data_df.columns) + ['hadm_id_window', 'window_start', 'window_end'])\n",
    "\n",
    "\n",
    "def concat_medications_per_discharge(filtered_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given pharmacy rows already filtered into discharge windows, \n",
    "    return one row per discharge (hadm_id) with all medications concatenated.\n",
    "    Assumes filtered_df has at least ['subject_id', 'hadm_id_window', 'medication'] columns.\n",
    "    \"\"\"\n",
    "    # Keep only relevant columns\n",
    "    cols = ['subject_id', 'hadm_id_window', 'medication']\n",
    "    filtered_df = filtered_df[cols].copy()\n",
    "\n",
    "    # Concatenate all medications per discharge\n",
    "    grouped = (\n",
    "        filtered_df\n",
    "        .groupby(['subject_id', 'hadm_id_window'], dropna=False)\n",
    "        .agg({'medication': lambda x: ', '.join(x.astype(str).unique())})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Rename hadm_id_window back to hadm_id\n",
    "    grouped = grouped.rename(columns={'hadm_id_window': 'hadm_id'})\n",
    "\n",
    "    return grouped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141170ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load discharge data\n",
    "discharge_df = load_discharge_table(\"data_samples/notes/discharge.csv\")\n",
    "\n",
    "# Build discharge windows\n",
    "windows = build_discharge_windows(discharge_df)\n",
    "\n",
    "# Load another table (e.g. pharmacy.csv)\n",
    "pharmacy_df = pd.read_csv(\"data_samples/hosp/pharmacy.csv\", parse_dates=['starttime'])\n",
    "\n",
    "# Extract pharmacy rows that fall into each discharge window\n",
    "pharmacy_in_windows = extract_rows_in_windows(pharmacy_df, windows, time_col='starttime')\n",
    "\n",
    "# Optionally group by discharge\n",
    "med_concat_per_discharge = concat_medications_per_discharge(pharmacy_in_windows)\n",
    "\n",
    "med_concat_per_discharge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_df = load_discharge_table(\"data_samples/notes/discharge.csv\")\n",
    "\n",
    "# Build discharge windows\n",
    "build_discharge_windows(discharge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e6e80",
   "metadata": {},
   "source": [
    "## Descrever, como foi feitas as janelas - como foi selecinadas os periodos e pq\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a33d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "HOSP = '../data_samples/hosp/'\n",
    "ICU = '../data_samples/icu/'\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity\n",
    "# Age & Gender\n",
    "# Race & Language: Important for social history and potential care barriers.\n",
    "# Admission Type & Location: (e.g., \"Urgent admission via the Emergency Room\"). How critical the situation was.\n",
    "# Baselines BMI/Weight...\n",
    "patients = pd.read_csv(HOSP+'patients.csv')\n",
    "admissions = pd.read_csv(HOSP+'admissions.csv')\n",
    "omr = pd.read_csv(HOSP+'omr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Standardize Timestamps\n",
    "admissions['admittime'] = pd.to_datetime(admissions['admittime'])\n",
    "patients['anchor_year'] = patients['anchor_year'].astype(int)\n",
    "\n",
    "# 2. Merge Admissions and Patients\n",
    "# We bring in gender and the age anchors\n",
    "identity_df = admissions.merge(\n",
    "    patients[['subject_id', 'gender', 'anchor_age', 'anchor_year', 'dod']], \n",
    "    on='subject_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Calculate Age at Admission\n",
    "# Age = anchor_age + (Year of Admission - anchor_year)\n",
    "identity_df['admission_year'] = identity_df['admittime'].dt.year\n",
    "identity_df['age_at_admission'] = (identity_df['anchor_age'] + (identity_df['admission_year'] - identity_df['anchor_year']))\n",
    "\n",
    "# 4. Integrate OMR (Baseline Vitals)\n",
    "# Height, Weight, BMI, Blood pressure\n",
    "baseline_omr = omr[omr['result_name'].isin(['Weight (Lbs)', 'Height (Inches)', 'BMI (kg/m2)', 'Blood Pressure'])].copy()\n",
    "baseline_omr = baseline_omr.sort_values('chartdate').groupby(['subject_id', 'result_name']).head(1)\n",
    "\n",
    "# Pivot so each measurement is its own column\n",
    "omr_pivot = baseline_omr.pivot(index='subject_id', columns='result_name', values='result_value').reset_index()\n",
    "\n",
    "# Merge OMR data into main identity frame\n",
    "identity_df = identity_df.merge(omr_pivot, on='subject_id', how='left')\n",
    "\n",
    "# 5. Set the Anchor Timestamp\n",
    "identity_df['timestamp'] = identity_df['admittime']\n",
    "\n",
    "# 6. Cleanup and Selection\n",
    "# Rename OMR columns to be more regex-friendly (remove spaces/units if preferred)\n",
    "identity_df = identity_df.rename(columns={\n",
    "    'Weight (Lbs)': 'weight_baseline',\n",
    "    'Height (Inches)': 'height_baseline',\n",
    "    'BMI (kg/m2)': 'bmi_baseline',\n",
    "    'Blood Pressure': 'blood_pressure_baseline',\n",
    "})\n",
    "\n",
    "relevant_cols = [\n",
    "    'subject_id', 'hadm_id', 'timestamp', 'age_at_admission', 'gender', 'race',\n",
    "    'admission_type', 'admission_location', 'insurance', 'marital_status',\n",
    "    'weight_baseline', 'height_baseline', 'bmi_baseline', 'blood_pressure_baseline', 'dod'\n",
    "]\n",
    "\n",
    "identity_df = identity_df[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfers, Services, and Admissions are grouped as Logistics, because a hospital stay is defined by movement through locations\n",
    "# and care teams; Transfers describe where the patient was (ED, ICU, ward), while Services identify which clinical team was responsible,\n",
    "# forming the structural backbone of the hospitalization narrative. Finally, all time-related fields are unified under a single\n",
    "# timestamp, since different tables record events using different time columns; standardizing these enables all events to be ordered\n",
    "# chronologically, transforming disconnected facts into a coherent, step-by-step timeline of the patient's hospital course.\n",
    "\n",
    "transfers = pd.read_csv(HOSP+'transfers.csv')\n",
    "services = pd.read_csv(HOSP+'services.csv')\n",
    "\n",
    "# 1. Standardize Timestamps\n",
    "transfers['intime'] = pd.to_datetime(transfers['intime'])\n",
    "transfers['outime'] = pd.to_datetime(transfers['outtime'])\n",
    "services['transfertime'] = pd.to_datetime(services['transfertime'])\n",
    "\n",
    "# 2. Fix HADM_ID types to avoid MergeError\n",
    "# We drop NaNs first because you can't join on an empty ID\n",
    "transfers = transfers.dropna(subset=['hadm_id'])\n",
    "services = services.dropna(subset=['hadm_id'])\n",
    "\n",
    "# Force to int64\n",
    "transfers['hadm_id'] = transfers['hadm_id'].astype('int64')\n",
    "services['hadm_id'] = services['hadm_id'].astype('int64')\n",
    "admissions['hadm_id'] = admissions['hadm_id'].astype('int64')\n",
    "\n",
    "# 3. Enrich Transfers with Admission/Discharge info\n",
    "logistics_df = transfers.merge(\n",
    "    admissions[['hadm_id', 'admission_location', 'discharge_location']], \n",
    "    on='hadm_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 4. Join Services (The \"As-Of\" Join)\n",
    "services = services.sort_values('transfertime')\n",
    "logistics_df = logistics_df.sort_values('intime')\n",
    "\n",
    "logistics_df = pd.merge_asof(\n",
    "    logistics_df,\n",
    "    services[['hadm_id', 'curr_service', 'transfertime']],\n",
    "    left_on='intime',\n",
    "    right_on='transfertime',\n",
    "    by='hadm_id',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# 5. Filter for real ward movements and calculate duration\n",
    "logistics_df = logistics_df.dropna(subset=['careunit'])\n",
    "logistics_df['stay_duration_hours'] = (logistics_df['outime'] - logistics_df['intime']).dt.total_seconds() / 3600\n",
    "\n",
    "# 6. Set the Anchor Timestamp\n",
    "logistics_df['timestamp'] = logistics_df['intime']\n",
    "\n",
    "relevant_cols = [\n",
    "    'subject_id', 'hadm_id', 'timestamp', 'eventtype', 'careunit', \n",
    "    'curr_service', 'intime', 'outime', 'stay_duration_hours',\n",
    "    'admission_location', 'discharge_location'\n",
    "]\n",
    "\n",
    "logistics_df = logistics_df[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_items = pd.read_csv(ICU+'d_items.csv')\n",
    "chartevents = pd.read_csv(ICU+'chartevents.csv')\n",
    "\n",
    "# 1. Filter d_items for common Vital Signs to keep the data manageable\n",
    "# In MIMIC-IV, these are the most common ICU vital codes\n",
    "vital_itemids = [220045, 220179, 220180, 220210, 223761] # HR, SysBP, DiasBP, RR, Temp\n",
    "vitals_dict = d_items[d_items['itemid'].isin(vital_itemids)]\n",
    "\n",
    "# 2. Join ICU Vitals\n",
    "icu_vitals = chartevents.merge(vitals_dict[['itemid', 'label']], on='itemid', how='inner')\n",
    "icu_vitals['timestamp'] = pd.to_datetime(icu_vitals['charttime'])\n",
    "\n",
    "# 3. Join Ward Vitals (from OMR)\n",
    "ward_vitals = omr[omr['result_name'].str.contains('Blood Pressure', na=False)].copy()\n",
    "ward_vitals['timestamp'] = pd.to_datetime(ward_vitals['chartdate'])\n",
    "\n",
    "# Merge with admissions to get the hadm_id for each OMR measurement\n",
    "# Note: Since OMR doesn't have hadm_id, we link via subject_id and time\n",
    "ward_vitals = ward_vitals.merge(admissions[['subject_id', 'hadm_id', 'admittime', 'dischtime']], on='subject_id', how='left')\n",
    "\n",
    "# Filter to keep only OMR records that happened DURING the admission\n",
    "ward_vitals['admittime'] = pd.to_datetime(ward_vitals['admittime'])\n",
    "ward_vitals['dischtime'] = pd.to_datetime(ward_vitals['dischtime'])\n",
    "\n",
    "mask = (ward_vitals['timestamp'] >= ward_vitals['admittime'].dt.normalize()) & \\\n",
    "       (ward_vitals['timestamp'] <= ward_vitals['dischtime'].dt.normalize())\n",
    "ward_vitals = ward_vitals[mask]\n",
    "\n",
    "# Now rename and select columns\n",
    "ward_vitals = ward_vitals.rename(columns={'result_name': 'label', 'result_value': 'valuenum'})\n",
    "\n",
    "# 4. Combine into a \"Master Vitals\" table\n",
    "# Now ward_vitals has 'hadm_id', so the concatenation won't crash\n",
    "monitoring_df = pd.concat([\n",
    "    icu_vitals[['subject_id', 'hadm_id', 'timestamp', 'label', 'valuenum', 'valueuom']],\n",
    "    ward_vitals[['subject_id', 'hadm_id', 'timestamp', 'label', 'valuenum']]\n",
    "], axis=0)\n",
    "\n",
    "monitoring_df = monitoring_df.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fe0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents = pd.read_csv(HOSP+'labevents.csv')\n",
    "d_labitems = pd.read_csv(HOSP+'d_labitems.csv')\n",
    "microbiology = pd.read_csv(HOSP+'microbiologyevents.csv')\n",
    "\n",
    "# 1. Standardize Lab Events\n",
    "labevents['timestamp'] = pd.to_datetime(labevents['charttime'])\n",
    "\n",
    "# Merge with dictionary to get names (Labels) and the specimen type (Fluid)\n",
    "labs_df = labevents.merge(\n",
    "    d_labitems[['itemid', 'label', 'fluid', 'category']], \n",
    "    on='itemid', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Select key columns for the summary\n",
    "# 'flag' is vital here: it tells us if a result was 'abnormal'\n",
    "labs_final = labs_df[[\n",
    "    'subject_id', 'hadm_id', 'timestamp', 'label', 'valuenum', \n",
    "    'valueuom', 'flag', 'fluid'\n",
    "]].copy()\n",
    "labs_final['type'] = 'LAB'\n",
    "\n",
    "# 2. Process Microbiology\n",
    "microbiology['timestamp'] = pd.to_datetime(microbiology['charttime'])\n",
    "\n",
    "# We focus on the specimen (what was tested) and the organism (what was found)\n",
    "# If org_name is NaN, it usually means \"No growth\"\n",
    "micro_final = microbiology[[\n",
    "    'subject_id', 'hadm_id', 'timestamp', 'spec_type_desc', \n",
    "    'org_name', 'ab_name', 'interpretation'\n",
    "]].copy()\n",
    "\n",
    "micro_final = micro_final.rename(columns={'spec_type_desc': 'label'})\n",
    "micro_final['type'] = 'MICRO'\n",
    "\n",
    "# 3. Combine into the Investigations Table\n",
    "investigations_df = pd.concat([labs_final, micro_final], axis=0)\n",
    "\n",
    "investigations_df = investigations_df.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "investigations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13627b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedures\n",
    "procedureevents = pd.read_csv(ICU+'procedureevents.csv')\n",
    "d_items = pd.read_csv(ICU+'d_items.csv')\n",
    "\n",
    "d_icd_procedures = pd.read_csv(HOSP+'d_icd_procedures.csv')\n",
    "procedures_icd = pd.read_csv(HOSP+'procedures_icd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. ICU Bedside Procedures\n",
    "procedureevents['timestamp'] = pd.to_datetime(procedureevents['starttime'])\n",
    "procedureevents['endtime'] = pd.to_datetime(procedureevents['endtime'])\n",
    "\n",
    "icu_procs = procedureevents.merge(d_items[['itemid', 'label']], on='itemid', how='left')\n",
    "icu_procs['proc_type'] = 'ICU_BEDSIDE'\n",
    "\n",
    "# 2. Billed Hospital Procedures (The \"Translation\" Fix)\n",
    "# Force versions to int and codes to padded strings\n",
    "for df in [procedures_icd, d_icd_procedures]:\n",
    "    df['icd_version'] = df['icd_version'].astype(int)\n",
    "    df['icd_code'] = df['icd_code'].astype(str).str.strip()\n",
    "    # Pad ICD-9 codes to 4 digits (e.g., '66' -> '0066')\n",
    "    mask_v9 = df['icd_version'] == 9\n",
    "    df.loc[mask_v9, 'icd_code'] = df.loc[mask_v9, 'icd_code'].str.zfill(4)\n",
    "\n",
    "billed_procs = procedures_icd.merge(\n",
    "    d_icd_procedures[['icd_code', 'icd_version', 'long_title']], \n",
    "    on=['icd_code', 'icd_version'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Billed procedures only have a 'chartdate'. We anchor them to 'admittime' \n",
    "# so they appear in the stay window, but label them as billed events.\n",
    "billed_procs = billed_procs.merge(admissions[['hadm_id', 'admittime']], on='hadm_id', how='left')\n",
    "billed_procs['timestamp'] = pd.to_datetime(billed_procs['admittime'])\n",
    "billed_procs = billed_procs.rename(columns={'long_title': 'label'})\n",
    "billed_procs['proc_type'] = 'BILLED_SURGICAL'\n",
    "\n",
    "# 3. Combine into Interventions Table\n",
    "interventions_df = pd.concat([\n",
    "    icu_procs[['subject_id', 'hadm_id', 'timestamp', 'label', 'proc_type', 'endtime']],\n",
    "    billed_procs[['subject_id', 'hadm_id', 'timestamp', 'label', 'proc_type']]\n",
    "], axis=0)\n",
    "\n",
    "interventions_df.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputevents = pd.read_csv(ICU+'inputevents.csv')\n",
    "d_items = pd.read_csv(ICU+'d_items.csv')\n",
    "\n",
    "prescriptions = pd.read_csv(HOSP+'prescriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ICU Continuous Inputs (IVs and Drips)\n",
    "inputevents['timestamp'] = pd.to_datetime(inputevents['starttime'])\n",
    "\n",
    "# Join with d_items to get drug names\n",
    "icu_inputs = inputevents.merge(d_items[['itemid', 'label']], on='itemid', how='left')\n",
    "\n",
    "# We keep amount and rate to describe the intensity of the treatment\n",
    "icu_inputs = icu_inputs[['subject_id', 'hadm_id', 'timestamp', 'label', 'amount', 'amountuom', 'rate', 'rateuom']]\n",
    "icu_inputs['input_type'] = 'ICU_INPUT'\n",
    "\n",
    "# 2. General Hospital Prescriptions\n",
    "prescriptions['timestamp'] = pd.to_datetime(prescriptions['starttime'])\n",
    "\n",
    "# We select the drug name, dose, and route (e.g., PO for mouth, IV for vein)\n",
    "ward_inputs = prescriptions[[\n",
    "    'subject_id', 'hadm_id', 'timestamp', 'drug', 'dose_val_rx', 'dose_unit_rx', 'route'\n",
    "]].copy()\n",
    "\n",
    "ward_inputs = ward_inputs.rename(columns={'drug': 'label'})\n",
    "ward_inputs['input_type'] = 'WARD_PRESCRIPTION'\n",
    "\n",
    "# 3. Combine into a Master Meds Table\n",
    "meds_df = pd.concat([icu_inputs, ward_inputs], axis=0)\n",
    "    \n",
    "meds_df.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3870db",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_icd = pd.read_csv(HOSP+'diagnoses_icd.csv')\n",
    "d_icd_diagnoses = pd.read_csv(HOSP+'d_icd_diagnoses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Clean and Pad ICD Codes (Same logic as Procedures)\n",
    "for df in [diagnoses_icd, d_icd_diagnoses]:\n",
    "    df['icd_version'] = df['icd_version'].astype(int)\n",
    "    df['icd_code'] = df['icd_code'].astype(str).str.strip()\n",
    "    # Pad ICD-9 codes to 3-5 digits depending on the code type if necessary\n",
    "    # Usually, a simple zfill handles the majority of join misses\n",
    "    mask_v9 = df['icd_version'] == 9\n",
    "    df.loc[mask_v9, 'icd_code'] = df.loc[mask_v9, 'icd_code'].str.zfill(3)\n",
    "\n",
    "# 2. Join with Dictionary\n",
    "outcomes_df = diagnoses_icd.merge(\n",
    "    d_icd_diagnoses[['icd_code', 'icd_version', 'long_title']], \n",
    "    on=['icd_code', 'icd_version'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Anchor to Discharge Time\n",
    "outcomes_df = outcomes_df.merge(\n",
    "    admissions[['hadm_id', 'dischtime']], \n",
    "    on='hadm_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "outcomes_df['timestamp'] = pd.to_datetime(outcomes_df['dischtime'])\n",
    "outcomes_df = outcomes_df.rename(columns={'long_title': 'diagnosis_label'})\n",
    "\n",
    "# 'seq_num' tells us the priority (1 is the primary diagnosis)\n",
    "outcomes_df[['subject_id', 'hadm_id', 'timestamp', 'diagnosis_label', 'seq_num']].sort_values('seq_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnosis_summary(outcomes_df, target_hadm_id):\n",
    "    # Filter for the specific admission\n",
    "    stay_outcomes = outcomes_df[outcomes_df['hadm_id'] == target_hadm_id].sort_values('seq_num')\n",
    "    \n",
    "    # Get the list of diagnosis labels\n",
    "    conditions = stay_outcomes['diagnosis_label'].tolist()\n",
    "    \n",
    "    if not conditions:\n",
    "        return \"No recorded diagnoses found for this stay.\"\n",
    "    \n",
    "    # Construct the clean string\n",
    "    condition_list = \", \".join(conditions)\n",
    "    summary_str = f\"During the stay, the patient was diagnosed with the following conditions: {condition_list}.\"\n",
    "    \n",
    "    return summary_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_builder_v2(window_cuts):\n",
    "    \"\"\"\n",
    "    Inputs: window_cuts -> dict of DataFrames (identity, logistics, monitoring, etc.)\n",
    "    already sliced for one specific patient and one specific time window.\n",
    "    Output: A single stitched string.\n",
    "    \"\"\"\n",
    "    paragraphs = []\n",
    "\n",
    "    # 1. Identity (The Intro)\n",
    "    # We assume identity is passed in the dict; usually contains 1 row per admission\n",
    "    if 'identity' in window_cuts and not window_cuts['identity'].empty:\n",
    "        id_df = window_cuts['identity']\n",
    "        row = id_df.iloc[0] # Take the most recent/relevant identity row\n",
    "        paragraphs.append(\n",
    "            f\"Patient is a {row.age_at_admission} year old {row.gender} ({row.race}) \"\n",
    "            f\"admitted via {row.admission_location}.\"\n",
    "        )\n",
    "\n",
    "    # 2. Logistics (The Journey)\n",
    "    if 'logistics' in window_cuts and not window_cuts['logistics'].empty:\n",
    "        log = window_cuts['logistics'].sort_values('timestamp')\n",
    "        units = \" -> \".join(log['careunit'].unique())\n",
    "        paragraphs.append(f\"Clinical course involved the following units: {units}.\")\n",
    "\n",
    "    # 3. Monitoring (The Vitals)\n",
    "    if 'monitoring' in window_cuts and not window_cuts['monitoring'].empty:\n",
    "        mon = window_cuts['monitoring'].sort_values('timestamp')\n",
    "        # Get the latest reading for each unique vital sign in this window\n",
    "        latest_vitals = mon.groupby('label').tail(1)\n",
    "        v_list = [f\"{r.label}: {r.valuenum}{getattr(r, 'valueuom', '')}\" for r in latest_vitals.itertuples()]\n",
    "        paragraphs.append(f\"Most recent vital signs: {', '.join(v_list)}.\")\n",
    "\n",
    "    # 4. Investigations (The Labs)\n",
    "    if 'investigations' in window_cuts and not window_cuts['investigations'].empty:\n",
    "        inv = window_cuts['investigations']\n",
    "        # Focus on abnormal results to keep the text high-signal\n",
    "        abnormal = inv[inv['flag'] == 'abnormal'].sort_values('timestamp')\n",
    "        if not abnormal.empty:\n",
    "            l_list = [f\"{r.label} ({r.valuenum})\" for r in abnormal.itertuples()]\n",
    "            paragraphs.append(f\"Significant lab abnormalities identified: {', '.join(l_list)}.\")\n",
    "\n",
    "    # 5. Inputs (The Meds)\n",
    "    if 'inputs' in window_cuts and not window_cuts['inputs'].empty:\n",
    "        meds = window_cuts['inputs']\n",
    "        med_names = meds['label'].unique()\n",
    "        paragraphs.append(f\"Treatments administered during this window included: {', '.join(med_names)}.\")\n",
    "\n",
    "    # 6. Interventions (The Actions)\n",
    "    if 'interventions' in window_cuts and not window_cuts['interventions'].empty:\n",
    "        procs = window_cuts['interventions']['label'].unique()\n",
    "        paragraphs.append(f\"Procedures performed: {', '.join(procs)}.\")\n",
    "\n",
    "    # 7. Conclusion (The Diagnoses)\n",
    "    if 'conclusion' in window_cuts and not window_cuts['conclusion'].empty:\n",
    "        diag = window_cuts['conclusion'].sort_values('seq_num')\n",
    "        diag_list = diag['diagnosis_label'].tolist()\n",
    "        paragraphs.append(f\"During the stay, the patient was diagnosed with the following conditions: {', '.join(diag_list)}.\")\n",
    "\n",
    "    # Stitch all paragraphs into one clean block\n",
    "    return \" \".join(paragraphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
